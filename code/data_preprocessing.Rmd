---
title: "Data preprocessing"
date: "2025-07-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(dplyr)
library(tidyr)
library(ggpubr)
library(purrr)
library(zoo)
library(stringr)
```

## Reading data files

```{r reading data}
# read fix report
fix_report_original <- read.delim("../data/fix_report.txt", fileEncoding = "UTF-16LE")
fix_report_clean <- fix_report_original

# read getreadingmeasures files
df_affix_clean <- read.csv("../data/rm_target_affix.csv", sep = "\t", fileEncoding = "UTF-16LE")
df_baseline_clean <- read.csv("../data/rm_baseline.csv", sep = "\t", fileEncoding = "UTF-16LE")
# baseline word is including the space before the word
df_root_clean <- read.csv("../data/rm_root.csv", sep = "\t", fileEncoding = "UTF-16LE")
df_rest_clean <- read.csv("../data/rm_rest.csv", sep = "\t", fileEncoding = "UTF-16LE")
df_whole_word_clean <- read.csv("../data/rm_whole_word.csv", sep = "\t", fileEncoding = "UTF-16LE")

# rename participant_id column
names(df_affix_clean)[names(df_affix_clean) == 'Session_Name_'] <- 'participant_id'
names(df_baseline_clean)[names(df_baseline_clean) == 'Session_Name_'] <- 'participant_id'
names(df_root_clean)[names(df_root_clean) == 'Session_Name_'] <- 'participant_id'
names(df_rest_clean)[names(df_rest_clean) == 'Session_Name_'] <- 'participant_id'
names(df_whole_word_clean)[names(df_whole_word_clean) == 'Session_Name_'] <- 'participant_id'
names(fix_report_clean)[names(fix_report_clean) == 'RECORDING_SESSION_LABEL'] <- 'participant_id'
names(fix_report_original)[names(fix_report_original) == 'RECORDING_SESSION_LABEL'] <- 'participant_id'
```

### Checking that GetReadingMeasures did in fact extract data from the right IAs

```{r check}
affix_check <- df_affix_clean %>%
  rowwise() %>%
  mutate(
    full_sentence = paste(sentence_1_kal, sentence_2_kal, sentence_3_kal, sep = ""),
    extracted_text = substr(full_sentence, REGION_START_IA_ID, REGION_END_IA_ID)
  ) %>%
  ungroup() %>%
  group_by(item_no, extracted_text) %>%
  summarise(n = n())

affix_check

baseline_check <- df_baseline_clean %>%
  rowwise() %>%
  mutate(
    full_sentence = paste(sentence_1_kal, sentence_2_kal, sentence_3_kal, sep = ""),
    extracted_text = substr(full_sentence, REGION_START_IA_ID, REGION_END_IA_ID)
  ) %>%
  ungroup() %>%
  group_by(item_no, extracted_text) %>%
  summarise(n = n())

baseline_check

root_check <- df_root_clean %>%
  rowwise() %>%
  mutate(
    full_sentence = paste(sentence_1_kal, sentence_2_kal, sentence_3_kal, sep = ""),
    extracted_text = substr(full_sentence, REGION_START_IA_ID, REGION_END_IA_ID)
  ) %>%
  ungroup() %>%
  group_by(item_no, extracted_text) %>%
  summarise(n = n())

root_check

rest_check <- df_rest_clean %>%
  rowwise() %>%
  mutate(
    full_sentence = paste(sentence_1_kal, sentence_2_kal, sentence_3_kal, sep = ""),
    extracted_text = substr(full_sentence, REGION_START_IA_ID, REGION_END_IA_ID)
  ) %>%
  ungroup() %>%
  group_by(item_no, extracted_text) %>%
  summarise(n = n())

rest_check

rest_check_grouped <- rest_check %>%
  group_by(extracted_text) %>%
  summarise(n = n())

whole_word_check <- df_whole_word_clean %>%
  rowwise() %>%
  mutate(
    full_sentence = paste(sentence_1_kal, sentence_2_kal, sentence_3_kal, sep = ""),
    extracted_text = substr(full_sentence, REGION_START_IA_ID, REGION_END_IA_ID)
  ) %>%
  ungroup() %>%
  group_by(item_no, extracted_text) %>%
  summarise(n = n())

whole_word_check
```


## Adding extra columns

```{r adding columns}
### add trial key column
df_affix_clean <- df_affix_clean %>%
  mutate(trial_key = paste(participant_id, item_no, sep = "_"))
df_baseline_clean <- df_baseline_clean %>%
  mutate(trial_key = paste(participant_id, item_no, sep = "_"))
df_root_clean <- df_root_clean %>%
  mutate(trial_key = paste(participant_id, item_no, sep = "_"))
df_rest_clean <- df_rest_clean %>%
  mutate(trial_key = paste(participant_id, item_no, sep = "_"))
df_whole_word_clean <- df_whole_word_clean %>%
  mutate(trial_key = paste(participant_id, item_no, sep = "_"))
fix_report_clean <- fix_report_clean %>%
  mutate(trial_key = paste(participant_id, item_no, sep = "_"))
fix_report_original <- fix_report_original %>%
  mutate(trial_key = paste(participant_id, item_no, sep = "_"))

### add column with log10-transformed predictability (only relevant for the affix df)
df_affix_clean <- df_affix_clean %>%
  mutate(predictability_log = log10(predictability + 1e-7))

### add column containing frequency for rest_word

# make df containing frequency of the fill affix + inflection combination
df_rest_word_frequency <- rest_check %>%
  mutate(rest_word_frequency_absolute = recode(
    extracted_text,
    "aluaramiuk" = 582,
    "aluarluni" = 8853,
    "galuaraangat" = 136,
    "galuarami" = 1035,
    "galuarpaat" = 1848,
    "galuarpoq" = 7305,
    "gunarami" = 198,
    "gunarluni" = 442,
    "gunarpoq" = 1826,
    "kunarput" = 38,
    "narput" = 15045,
    "neqarput" = 56052,
    "nersoq" = 41342,
    "nersut" = 29769,
    "niarli" = 674,
    "niarpaa" = 6384,
    "niarpai" = 1416,
    "niarpoq" = 2981,
    "niarput" = 2131,
    "nikuuaat" = 514,
    "nikuugamik" = 133,
    "nikuulluni" = 481,
    "nikuullutik" = 209,
    "nikuummat" = 452,
    "nikuupput" = 1855,
    "nikuuput" = 4,
    "nikuuvaa" = 126,
    "nikuuvoq" = 3010,
    "nikuuvunga" = 590,
    "nnguatsiarluni" = 164,
    "nnguatsiarlutik" = 52,
    "nnguatsiarmat" = 187,
    "nnguatsiarpoq" = 436,
    "qaat" = 28459,
    "qalutik" = 2842,
    "qisoq" = 6832,
    "qqammerpoq" = 1297,
    "qqammerput" = 724,
    "raluarami" = 563,
    "raluarlutik" = 1879,
    "raluarpaa" = 1365,
    "raluarpoq" = 5575,
    "raluarput" = 2719,
    "riikatappaa" = 16,
    "rumaarpaa" = 211,
    "runarmata" = 35,
    "sarpoq" = 15795,
    "simagami" = 2050,
    "simagamik" = 1201,
    "simalluni" = 13326,
    "simallutik" = 9823,
    "simammat" = 4276,
    "simannguatsiarpoq" = 41,
    "simapput" = 37577,
    "simasut" = 57619,
    "simavaa" = 13217,
    "simavaat" = 12155,
    "simavai" = 5760,
    "simavoq" = 53664,
    "sinnaasoq" = 12501,
    "sinnarluni" = 837,
    "sinnarlutik" = 485,
    "ssaaq" = 127782,
    "ssagaa" = 3170,
    "ssagaluarpaa" = 331,
    "ssalluni" = 17323,
    "ssallutik" = 13704,
    "ssammat" = 6127,
    "ssammata" = 4909,
    "ssapput" = 82945,
    "ssasut" = 24000,
    "ssavai" = 8732,
    "tarpaa" = 3806,
    "tarpai" = 4203,
    "tarpoq" = 26636,
    "tarput" = 31396,
    "vippoq" = 3062,
    .default = NA_real_
  ))

# add column with log10 transformed frequency
df_rest_word_frequency <- df_rest_word_frequency %>%
  mutate(rest_word_frequency_log = log10(rest_word_frequency_absolute))

# add these frequency columns to the other dfs
df_affix_clean <- df_affix_clean %>%
  left_join(
    df_rest_word_frequency %>% select(item_no, rest_word_frequency_absolute, rest_word_frequency_log),
    by = "item_no"
  )
df_baseline_clean <- df_baseline_clean %>%
  left_join(
    df_rest_word_frequency %>% select(item_no, rest_word_frequency_absolute, rest_word_frequency_log),
    by = "item_no"
  )
df_root_clean <- df_root_clean %>%
  left_join(
    df_rest_word_frequency %>% select(item_no, rest_word_frequency_absolute, rest_word_frequency_log),
    by = "item_no"
  )
df_rest_clean <- df_rest_clean %>%
  left_join(
    df_rest_word_frequency %>% select(item_no, rest_word_frequency_absolute, rest_word_frequency_log),
    by = "item_no"
  )
df_whole_word_clean <- df_whole_word_clean %>%
  left_join(
    df_rest_word_frequency %>% select(item_no, rest_word_frequency_absolute, rest_word_frequency_log),
    by = "item_no"
  )
fix_report_clean <- fix_report_clean %>%
  left_join(
    df_rest_word_frequency %>% select(item_no, rest_word_frequency_absolute, rest_word_frequency_log),
    by = "item_no"
  )

```

## Data cleaning

### Removing data from participants whose accuracy on comprehension questions is at chance level

```{r data cleaning 1}
accuracy_count <- df_affix_clean %>%
  group_by(participant_id) %>%
  summarise(correct = sum(ACCURACY == 1),
            incorrect = sum(ACCURACY == 0),
            accuracy_percentage = (correct / (correct + incorrect)) * 100)

# binomial test to determine cutoff point
min_number_correct <- min(which(sapply(0:40, function(x) binom.test(x, 40, 0.5)$p.value) < 0.05 & 0:40 > 20))
# which accuracy percentage does this correspond to?
min_accuracy <- min_number_correct / 40 * 100

# participants to discard on this basis
participants_to_remove <- accuracy_count %>%
  filter(accuracy_percentage < min_accuracy)

df_affix_clean <- df_affix_clean %>%
  filter(!participant_id %in% participants_to_remove$participant_id)
df_baseline_clean <- df_baseline_clean %>%
  filter(!participant_id %in% participants_to_remove$participant_id)
df_root_clean <- df_root_clean %>%
  filter(!participant_id %in% participants_to_remove$participant_id)
df_rest_clean <- df_rest_clean %>%
  filter(!participant_id %in% participants_to_remove$participant_id)
df_whole_word_clean <- df_whole_word_clean %>%
  filter(!participant_id %in% participants_to_remove$participant_id)
fix_report_clean <- fix_report_clean %>%
  filter(!participant_id %in% participants_to_remove$participant_id)
```

### Removing trials where there was a disturbance (noted in log) or participant pressed space too soon

```{r data cleaning 2}
# read csv with these trials
df_trials_noted_in_log <- read.csv("../data/trials_noted_in_log.csv", sep = ";", fileEncoding = "UTF-8")

# get item_no for all trials and create trial_key
df_trials_noted_in_log <- df_trials_noted_in_log %>%
  left_join(
    df_affix_clean %>% select(participant_id, TRIAL_INDEX, item_no_affix = item_no),
    by = c("participant_id", "TRIAL_INDEX")
  ) %>%
  mutate(
    # filling missing item_no from df_affix_clean if necessary
    item_no = ifelse(is.na(item_no), item_no_affix, item_no)
  ) %>%
  select(-item_no_affix) %>%  # removing temporary column
  mutate(
    # creating trial_key
    trial_key = paste0(participant_id, "_", item_no)
  )

# remove trials from df_affix_clean, df_baseline_clean, etc.
df_affix_clean <- df_affix_clean %>%
  filter(!trial_key %in% df_trials_noted_in_log$trial_key)
df_baseline_clean <- df_baseline_clean %>%
  filter(!trial_key %in% df_trials_noted_in_log$trial_key)
df_root_clean <- df_root_clean %>%
  filter(!trial_key %in% df_trials_noted_in_log$trial_key)
df_rest_clean <- df_rest_clean %>%
  filter(!trial_key %in% df_trials_noted_in_log$trial_key)
df_whole_word_clean <- df_whole_word_clean %>%
  filter(!trial_key %in% df_trials_noted_in_log$trial_key)
fix_report_clean <- fix_report_clean %>%
  filter(!trial_key %in% df_trials_noted_in_log$trial_key)

```

### Excluding rereading from fix report

```{r excluding rereading}
# if they go back to fixating on sentence 1 and 2 after reading sentence 3, I
# want to exclude those fixations

# calculate the IA id ranges for each sentence
fix_report_clean <- fix_report_clean %>%
  rowwise() %>%
  mutate(
    len1 = nchar(sentence_1_kal),
    len2 = nchar(sentence_2_kal),
    len3 = nchar(sentence_3_kal),
    sentence_1_ids = list(1:len1),
    sentence_2_ids = list((len1 + 1):(len1 + len2)),
    sentence_3_ids = list((len1 + len2 + 1):(len1 + len2 + len3))
  ) %>%
  ungroup()

# function to identify if CURRENT_INTEREST_AREA is in any sentence
get_sentence_label <- function(interest_area, s1, s2, s3) {
  if (interest_area %in% s1) return(1)
  if (interest_area %in% s2) return(2)
  if (interest_area %in% s3) return(3)
  return(NA)
}

# applying sentence label to each fixation
fix_report_clean <- fix_report_clean %>%
  rowwise() %>%
  mutate(
    sentence_label = get_sentence_label(CURRENT_FIX_INTEREST_AREA_ID, sentence_1_ids, sentence_2_ids, sentence_3_ids)
  ) %>%
  ungroup()

# modifying fix_report so it contains only initial pass fixations per trial (no rereading)

# function to find rereading start index
find_rereading_start <- function(sentence_seq) {
  # Step 1: Find the first index where there are 3 consecutive 3s (reading of sentence 3)
  runs_3 <- rollapply(sentence_seq, width = 3, FUN = function(x) all(x == 3), fill = NA, align = "left")
  first_s3_idx <- which(runs_3)[1]
  if (is.na(first_s3_idx)) return(Inf)  # No proper sentence 3 reading found
  
  # Step 2: Search for 3 consecutive 1s or 2s after first_s3_idx
  post_s3_seq <- sentence_seq[(first_s3_idx + 3):length(sentence_seq)]
  runs_12 <- rollapply(post_s3_seq, width = 3, FUN = function(x) all(x %in% c(1, 2)), fill = NA, align = "left")
  reread_start_idx <- which(runs_12)[1]
  
  if (!is.na(reread_start_idx)) {
    return(first_s3_idx + 3 + reread_start_idx - 1)
  } else {
    return(Inf)  # No rereading found
  }
}

# apply to fix_report
fix_report_clean <- fix_report_clean %>%
  group_by(trial_key, participant_id) %>%
  mutate(row_index = row_number()) %>%
  mutate(rereading_start = {
    reread_idx <- find_rereading_start(sentence_label)
    ifelse(row_index >= reread_idx, TRUE, FALSE)
  }) %>%
  filter(!rereading_start) %>%
  select(-rereading_start, -row_index)

# overview of number of fixations during initial pass reading of each trial
fix_count <- fix_report_clean %>%
  group_by(trial_key, participant_id) %>%
  summarise(initial_fix_count = n())

# same overview for fix_report_original (with rereading)
fix_count_original <- fix_report_original %>%
  group_by(trial_key) %>%
  summarise(fix_count = n())

# compare
fix_count_joined <- fix_count %>%
  inner_join(fix_count_original, by = "trial_key") %>%
  mutate(diff = abs(fix_count - initial_fix_count))

mean(fix_count_joined$diff)

fix_count_joined_participant <- fix_count_joined %>%
  group_by(participant_id) %>%
  summarise(mean_diff = mean(diff))

top_5_diff <- fix_count_joined %>%
  arrange(desc(diff)) %>%
  head(5)
top_5_diff

```

### Removing all trials where there was not a fixation on every line

```{r data cleaning 3}
# for each trial, check if each sentence was fixated
incomplete_trials <- fix_report_clean %>%
  group_by(participant_id, item_no, trial_key) %>%
  summarise(
    fixated_s1 = any(CURRENT_FIX_INTEREST_AREA_ID %in% unlist(sentence_1_ids)),
    fixated_s2 = any(CURRENT_FIX_INTEREST_AREA_ID %in% unlist(sentence_2_ids)),
    fixated_s3 = any(CURRENT_FIX_INTEREST_AREA_ID %in% unlist(sentence_3_ids)),
    all_lines_fixated = fixated_s1 & fixated_s2 & fixated_s3
  ) %>%
  filter(!all_lines_fixated)

# remove incomplete trials
df_affix_clean <- df_affix_clean %>%
  filter(!trial_key %in% incomplete_trials$trial_key)
df_baseline_clean <- df_baseline_clean %>%
  filter(!trial_key %in% incomplete_trials$trial_key)
df_root_clean <- df_root_clean %>%
  filter(!trial_key %in% incomplete_trials$trial_key)
df_rest_clean <- df_rest_clean %>%
  filter(!trial_key %in% incomplete_trials$trial_key)
df_whole_word_clean <- df_whole_word_clean %>%
  filter(!trial_key %in% incomplete_trials$trial_key)
fix_report_clean <- fix_report_clean %>%
  filter(!trial_key %in% incomplete_trials$trial_key)
```

### Removing trials where number of fixations pr. character is more than 3 SDs from the participant's mean

```{r data cleaning 4}
# get number of fixations and number of interest areas per trial
fixation_density <- fix_report_clean %>%
  group_by(participant_id, trial_key, item_no) %>%
  summarise(
    n_fixations_trial = n(),
    n_chars_trial = max(unlist(sentence_3_ids)),  # total number of characters in this trial
    fix_per_char_trial = n_fixations_trial / n_chars_trial,
    .groups = "drop"
  )

# add these columns to fix_report_clean, df_affix_clean, etc., for later use
df_affix_clean <- merge(df_affix_clean, fixation_density[, c("trial_key", "n_chars_trial", "n_fixations_trial", "fix_per_char_trial")], by = "trial_key")
df_baseline_clean <- merge(df_baseline_clean, fixation_density[, c("trial_key", "n_chars_trial", "n_fixations_trial", "fix_per_char_trial")], by = "trial_key")
df_root_clean <- merge(df_root_clean, fixation_density[, c("trial_key", "n_chars_trial", "n_fixations_trial", "fix_per_char_trial")], by = "trial_key")
df_rest_clean <- merge(df_rest_clean, fixation_density[, c("trial_key", "n_chars_trial", "n_fixations_trial", "fix_per_char_trial")], by = "trial_key")
df_whole_word_clean <- merge(df_whole_word_clean, fixation_density[, c("trial_key", "n_chars_trial", "n_fixations_trial", "fix_per_char_trial")], by = "trial_key")
fix_report_clean <- merge(fix_report_clean, fixation_density[, c("trial_key", "n_chars_trial", "n_fixations_trial", "fix_per_char_trial")], by = "trial_key")


# compute participant-level mean and SD
fix_density_stats <- fixation_density %>%
  group_by(participant_id) %>%
  mutate(
    mean_fix_char = mean(fix_per_char_trial, na.rm = TRUE),
    sd_fix_char = sd(fix_per_char_trial, na.rm = TRUE),
    z_score = (fix_per_char_trial - mean_fix_char) / sd_fix_char,
    is_outlier = abs(z_score) > 3
  ) %>%
  ungroup()

# keep only trials within 3 SDs
clean_trials <- fix_density_stats %>%
  filter(!is_outlier) %>%
  select(participant_id, trial_key)

# filter fix_report, df_affix_clean, etc.,  accordingly
fix_report_clean <- fix_report_clean %>%
  semi_join(clean_trials, by = c("participant_id", "trial_key"))
df_affix_clean <- df_affix_clean %>%
  semi_join(clean_trials, by = c("participant_id", "trial_key"))
df_baseline_clean <- df_baseline_clean %>%
  semi_join(clean_trials, by = c("participant_id", "trial_key"))
df_root_clean <- df_root_clean %>%
  semi_join(clean_trials, by = c("participant_id", "trial_key"))
df_rest_clean <- df_rest_clean %>%
  semi_join(clean_trials, by = c("participant_id", "trial_key"))
df_whole_word_clean <- df_whole_word_clean %>%
  semi_join(clean_trials, by = c("participant_id", "trial_key"))

```

### Removing problematic trials

```{r data cleaning 5}
# reading csv with problematic trials
problematic_trials <- read.csv("../data/trials_to_discard.csv", sep = ";", fileEncoding = "UTF-8")
# adding trial key
problematic_trials <- problematic_trials %>%
  mutate(trial_key = paste(participant_id, item_no, sep = "_"))

# adding column to df_affix_clean, df_root_clean and df_baseline_clean indicating if trial is problematic
df_affix_clean <- df_affix_clean %>%
  mutate(is_problematic = ifelse(trial_key %in% problematic_trials$trial_key, 1, 0))
df_baseline_clean <- df_baseline_clean %>%
  mutate(is_problematic = ifelse(trial_key %in% problematic_trials$trial_key, 1, 0))
df_root_clean <- df_root_clean %>%
  mutate(is_problematic = ifelse(trial_key %in% problematic_trials$trial_key, 1, 0))
df_rest_clean <- df_rest_clean %>%
  mutate(is_problematic = ifelse(trial_key %in% problematic_trials$trial_key, 1, 0))
df_whole_word_clean <- df_whole_word_clean %>%
  mutate(is_problematic = ifelse(trial_key %in% problematic_trials$trial_key, 1, 0))

# overview of how many problematic trials per participant
problem_trials_per_participant <- df_affix_clean %>%
  group_by(participant_id) %>%
  summarise(problem_count = sum(is_problematic))

problem_trials_per_participant

# removing problematic trials from df_affix_clean, df_root_clean, df_baseline_clean and fix_report_clean
df_affix_clean <- df_affix_clean %>%
  filter(is_problematic == 0)
df_baseline_clean <- df_baseline_clean %>%
  filter(is_problematic == 0)
df_root_clean <- df_root_clean %>%
  filter(is_problematic == 0)
df_rest_clean <- df_rest_clean %>%
  filter(is_problematic == 0)
df_whole_word_clean <- df_whole_word_clean %>%
  filter(is_problematic == 0)
fix_report_clean <- fix_report_clean %>%
  filter(!trial_key %in% problematic_trials$trial_key)

```

### Adding columns containing reading time and fixation numbers for entire trial

```{r add rt columns}
### add column containing mean reading time and number of fixations for entire trial

# get rt per character for each trial
reading_time_items <- fix_report_clean %>%
  group_by(trial_key, item_no) %>%
  summarise(
    total_initial_fixations_trial = n(),
    total_initial_duration_trial = sum(CURRENT_FIX_DURATION, na.rm = TRUE),
    n_chars_trial = max(unlist(sentence_3_ids)),  # total number of characters in this trial
    rt_per_char_trial = total_initial_duration_trial / n_chars_trial
  )

# add these columns to fix_report_clean, df_affix_clean, etc.
df_affix_clean <- merge(df_affix_clean, reading_time_items[, c("trial_key", "total_initial_duration_trial", "rt_per_char_trial")], by = "trial_key")
df_baseline_clean <- merge(df_baseline_clean, reading_time_items[, c("trial_key", "total_initial_duration_trial", "rt_per_char_trial")], by = "trial_key")
df_root_clean <- merge(df_root_clean, reading_time_items[, c("trial_key", "total_initial_duration_trial", "rt_per_char_trial")], by = "trial_key")
df_rest_clean <- merge(df_rest_clean, reading_time_items[, c("trial_key", "total_initial_duration_trial", "rt_per_char_trial")], by = "trial_key")
df_whole_word_clean <- merge(df_whole_word_clean, reading_time_items[, c("trial_key", "total_initial_duration_trial", "rt_per_char_trial")], by = "trial_key")
fix_report_clean <- merge(fix_report_clean, reading_time_items[, c("trial_key", "total_initial_duration_trial", "rt_per_char_trial")], by = "trial_key")
```


## Saving clean data frames

```{r saving data frames}
write.table(df_affix_clean, "../data/rm_target_affix_clean.tsv", sep = "\t", row.names = FALSE, quote = FALSE)
write.table(df_baseline_clean, "../data/rm_baseline_clean.tsv", sep = "\t", row.names = FALSE, quote = FALSE)
write.table(df_root_clean, "../data/rm_root_clean.tsv", sep = "\t", row.names = FALSE, quote = FALSE)
write.table(df_rest_clean, "../data/rm_rest_clean.tsv", sep = "\t", row.names = FALSE, quote = FALSE)
write.table(df_whole_word_clean, "../data/rm_whole_word_clean.tsv", sep = "\t", row.names = FALSE, quote = FALSE)

# convert the list columns to strings in order to save fix_report_clean as a .tsv file
fix_report_clean[] <- lapply(fix_report_clean, function(col) {
  if (is.list(col)) sapply(col, toString) else col
})
write.table(fix_report_clean, "../data/fix_report_clean.tsv", sep = "\t", row.names = FALSE, quote = FALSE)
```


